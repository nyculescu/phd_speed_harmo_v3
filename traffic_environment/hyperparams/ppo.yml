TrafficEnv-v0:
  n_timesteps: 1000000  # Total number of timesteps to train for
  policy: 'MlpPolicy'  # The policy architecture to use
  learning_rate: 3e-4  # Learning rate for the optimizer
  n_steps: 2048  # Number of steps to run for each environment per update
  batch_size: 64  # Minibatch size
  n_epochs: 10  # Number of epochs to optimize the surrogate loss
  gamma: 0.99  # Discount factor
  gae_lambda: 0.95  # Factor for trade-off of bias vs variance for Generalized Advantage Estimator
  clip_range: 0.2  # Clipping parameter, usually small, like 0.1 or 0.2
  ent_coef: 0.01  # Entropy coefficient for exploration
  vf_coef: 0.5  # Value function coefficient in the loss function
  max_grad_norm: 0.5  # Maximum norm for gradient clipping
  verbose: 1  # Verbosity level (0 = no output, 1 = info)